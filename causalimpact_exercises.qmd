---
title: "Causal Impact Assessment"
subtitle: "SIKS workshop May 31"
author: " Ois√≠n Ryan"
eval: false
format: 
  html:
    toc: true
    self-contained: true
    code-fold: true
    df-print: paged
    callout-appearance: simple
    callout-icon: false
---

In this practical we will use different methods to estimate the causal effect of the California proposition 99 policy intervention using **R**. For the difference-in-difference and synthetic control methods, comparable exercises in **python** are available [here](https://matheusfacure.github.io/python-causality-handbook/13-Difference-in-Differences.html) and [here](https://matheusfacure.github.io/python-causality-handbook/15-Synthetic-Control.html), though these are provided only for your reference.

::: {.callout-tip appearance="default" icon=true}
The answers to each exercise are available as a collapsed `code` block.
:::


In this practical we make extensive use of the `tidyverse` set of packages for manipulating data objects. If you have not yet installed these packages, please do so using `install.packages()` (e.g. `install_packages("tidyverse")`) before loading them. You can load the packages like so:

```{r}
#| label: setup
#| message: false
#| warning: false
#| code-fold: false
#| eval: true
library(tidyverse)
```

To aid in estimation of causal effects, we will also use the below packages. Again, please ensure they are installled and loaded.

```{r}
#| label: setup-2
#| code-fold: false
library(sandwich) # For pre-post and DiD
library(lmtest) # For pre-post and DiD
library(tidysynth) # For synthetic control analysis
```

## The data
We will be using the `proposition99` dataset that we introduced in the lecture. It is an `rds` file, which is a convenient, portable, and fast binary file format for R. 

::: {.callout-note}
## Exercise 1
Load the dataset in R using the `tidyverse` function `read_rds()`. Give the dataset the name `prop99`. Then, inspect the first few rows of the data.


```{r}
#| label: data
#| echo: true
#| eval: true

# read the dataset to a variable called prop99
prop99 <- read_rds("raw_data/proposition99.rds")

# inspect the first few rows
head(prop99)
```
:::

## Pre-post estimator
In this section, you will estimate the causal effect of the policy using the pre-post estimator. For this, you need to select only California from the data, then create a factor variable for the pre and post period, and then use linear regression to estimate the causal effect.

::: {.callout-note}
## Exercise 2
Use `filter()` to select only California from the dataset and use `mutate()` to create a pre-post indicator variable called `prepost`. Remember: include the year 1988 in the pre-period. Make sure your `prepost` variable is of the type `factor`. Assign the result to a variable called `prop99_cali`.

```{r}
#| label: prepostprep

# create the pre-post dataset
prop99_cali <- 
  prop99 |> 
  filter(state == "California") |> 
  mutate(prepost = factor(year > 1988, labels = c("Pre", "Post"))) 
```
:::

In the lecture, we chose to include 12 years before and after the intervention. In this practical, we will use only 5 years before and after the intervention for our effect estimate.

::: {.callout-note}
## Exercise 3
Use `filter()` to include data between 1984 and 1993. Then, use linear regression (`lm()`) to estimate the effect of the proposition 99 intervention, then use `summary` on the fitted model object to look at the estimate. Is this effect different from the one estimated in the lecture?

```{r}
#| label: prepostest

# fit the model with 5 years pre and post
fit_prepost <- lm(
  formula = cigsale ~ prepost, 
  data = prop99_cali |> filter(year > 1983, year < 1994)
)

# investigate the effect
summary(fit_prepost)

# the effect estimated in this way is -27.020
# this is much smaller than in the lecture!
```
:::


So far, we did not correct the inference (p-value) for potential unmodelled autocorrelation. We can do this with the function `coeftest()` on our fitted model object.

::: {.callout-note}
## Exercise 4
Use `coeftest()` to correct the inference using heteroscedasticity and autocorrelation consistent (HAC) standard errors (pass the `vcovHAC` function from the `sandwich` package to the `.vcov` argument). Is the pre-post causal effect significantly different from 0?

```{r}
#| label: HAC-correct
coeftest(fit_prepost, vcov. = vcovHAC)

# The standard error is a little bigger
# (it is now 5.29 versus 4.34 before)
# but the effect is still significant at 
# the 5% level. (p < .001)
```
:::

## Difference-in-differences estimator

In this section, we select a suitable control state to perform a diff-in-diff estimate of the causal effect of the policy intervention. In this section, you will not choose Utah as a control state as in the lectures, but one of the following states:

- Nevada
- Montana
- Colorado

Here are the data plots for these three states:

```{r}
#| label: didplots
#| eval: true

# Diff-in-diff time series figure
prop99 |> 
  filter(state %in% c("California", "Nevada", "Montana", "Colorado")) |> 
  ggplot(aes(x = year, y = cigsale, colour = state)) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1988, lty = 2) +
  theme_minimal() +
  scale_colour_manual(values = c("orange", "#AA8888",  "#88AA88","#8888AA")) +
  annotate("label", x = 1988, y = 150, label = "Intervention") +
  labs(title = "Panel data for California three potential control states",
       y = "Cigarette sales", x = "Year", colour = "")
```


::: {.callout-note}
## Exercise 5
Create a dataset called `prop99_did` which includes California and your chosen control state. As before, create a `prepost` variable and include only the 5 years before and after the intervention.

```{r}
#| label: didprep

# prepare the did data
prop99_did <- 
  prop99 |> 
  filter(
    state == "California" | state == "Nevada", 
    year > 1983, year < 1994
  ) |> 
  mutate(prepost = factor(year > 1988, labels = c("Pre", "Post"))) |> 
  filter()
```
:::


::: {.callout-note}
## Exercise 6
Now, estimate the causal effect using the difference-in-differences estimator. For this, use the formula `cigsale ~ state * prepost` in the `lm()` function. Investigate the estimated effect using HAC standard errors as before. How big is the causal effect of the policy intervention and is this effect significantly different from 0?
```{r}
#| label: didestimate

# fit the model with 5 years pre and post
fit_did <- lm(
  formula = cigsale ~ state * prepost, 
  data = prop99_did
)

# investigate the effect
coeftest(fit_did, vcov. = vcovHAC)

# Using Nevada as a control,
# the did causal effect is 5.68,
# with a HAC s.e. of 5.42
# so this effect is not significantly
# different from 0.
```
:::


## Synthetic Control (with tidysynth)

The first step in the `tidysynth` package framework is to create an object from the dataset that will provide the basis of the estimation method.

::: {.callout-note}
## Exercise 7
Use the the `synthetic_control()` function to create a synthetic control object from the `prop99` data called `prop99_syn`. Read the help file to (`?synthetic_control`) if you need to know more about the arguments needed. Set the argument `generate_placebos = TRUE` (we will need this later).

```{r}
#| label: synthcontrol-object

# create a synthetic control object
prop99_syn <- 
  prop99 |> 
  synthetic_control(
    outcome = cigsale,
    unit = state,
    time = year,
    i_unit = "California",
    i_time = 1988,
    generate_placebos = TRUE
  )

```
:::

In tidysynth, the `grab_*()` functions can be used to inspect the object in detail. For example, you can use `grab_outcome()` we inspect the outcome (cigsale) for the treated unit and the potential controls.

::: {.callout-note}
## Exercise 8
Inspect the outcome variable for the treated and the control units, to check that everything worked as you expected.

```{r}
#| label: inspect-outcome

# Treated unit (california)
grab_outcome(prop99_syn)

# control units
grab_outcome(prop99_syn, type = "controls")
```
:::

The next step is to determine and create the variables that will be used for matching and estimating weights. These are called "predictors" in `tidysynth`. 


::: {.callout-note}
## Exercise 9
Generate the following predictors using the `generate_predictor()` function. Assign the result to the `prop99_syn` object (think of this function as editing the object). You will need to run this function multiple times, once for each time period considered.

- Mean (log-)income in 1980-1988
- Mean retail price of cigarettes in 1980-1988
- Mean proportion of people aged 15 to 24 in 1980-1988
- Mean beer consumption in 1984-1988
- Cigarette sales in 1975
- Cigarette sales in 1980
- Cigarette sales in 1988

NB: there are some missing values in this data, so use `na.rm = TRUE` inside your `mean()` function.

```{r}
#| label: predictors

# create predictors
prop99_syn <- 
  prop99_syn |> 
  # The first three predictors
  generate_predictor(
    time_window = 1980:1988,
    lnincome = mean(lnincome, na.rm = TRUE),
    retprice = mean(retprice, na.rm = TRUE),
    age15to24 = mean(age15to24, na.rm = TRUE)
  ) |> 
  # Beer consumption in 1984-1988
  generate_predictor(
    time_window = 1984:1988,
    beer = mean(beer, na.rm = TRUE)
  ) |> 
  # Cigarette sales in 1975
  generate_predictor(
    time_window = 1975,
    cigsale_1975 = cigsale
  ) |> 
  # Cigarette sales in 1980
  generate_predictor(
    time_window = 1980,
    cigsale_1980 = cigsale
  ) |> 
  # Cigarette sales in 1988
  generate_predictor(
    time_window = 1988,
    cigsale_1988 = cigsale
  )
```
:::

Now you have created a synthetic control object that includes both the target variable and covariates (predictors) for the treated unit and the units in the donor pool. The next step is to add the weights that define the synthetic control unit.


::: {.callout-note}
## Exercise 10
Estimate synthetic control weights using the `generate_weights()` function. Just like the predictors, you should add these weights to the `prop99_syn` object. Inspect the unit and variable weights using the `plot_weights()` function.

```{r}
#| label: weights

# generate the weights using the pre-intervention
# time period as the optimization window
prop99_syn <- 
  prop99_syn |> 
  generate_weights(optimization_window = 1970:1988)

# inspect the unit and variable weights
plot_weights(prop99_syn)
```
:::

Now, everything is in place to create the synthetic control time-series.

::: {.callout-note}
## Exercise 11
Create the synthetic control time-series for California cigarette sales using the function `generate_control()`. Then, inspect the result using `grab_synthetic_control()` and `plot_trends()`.

```{r}
#| label: syncontrol-timeseries

# generate and inspect the dataset
prop99_syn <- generate_control(prop99_syn)
grab_synthetic_control(prop99_syn)

# plot the synthetic and observed cigsales
plot_trends(prop99_syn)
```
:::



### Inference using permutation test

Now we have our synthetic control timeseries $\hat{Y}^0_t$, we can estimate the average causal effect in the post-intervention period 1989-2000.


::: {.callout-note}
## Exercise 12
Estimate the average causal effect in the post-intervention time period:

$$\bar{CE} = \frac{1}{T} \sum_{t = 1}^{T} Y^1_t - Y^0_t$$
```{r}
#| label: causaleffect

# estimating the average causal effect
grab_synthetic_control(prop99_syn) |> 
  filter(time_unit > 1988) |>
  mutate(dif = real_y - synth_y) |> 
  summarize(CE = mean(dif))

```

:::


With `tidysynth`, it's easy to perform a permutation test. In fact, you have already done this by specifying `generate_placebos = TRUE`.

::: {.callout-note}
## Exercise 13
Use the function `plot_placebos()` to compare the counterfactual estimate to the reference distribution obtained via a permutation test. 


```{r}
#| label: permutationtest

# Placebo plot
plot_placebos(prop99_syn)
```
:::

### Robustness checks for units and variables

As mentioned in the lecture, this whole procedure hinges on a lot of choices. Through a robustness check (or sensitivity analysis) you can find out if your conclusions would have been different if you had made a different choice somewhere in the study.

::: {.callout-note}
## Exercise 14
Change one of the choices, rerun the analysis, and compare the results to the results you just created. For example:

- Change the donor pool by taking out Utah and Nevada
- Change the covariates by adding more, removing some, or changing the time window
- Set the variable weights to the inverse of the covariate's variances instead of RMSPE estimation

```{r}
#| label: robust

# do all three of the above.
prop99_syn_robust <- 
  prop99 |> 
  # remove utah and nevada
  filter(state != "Utah", state != "Nevada") |> 
  # create synthetic control object
  synthetic_control(
    outcome = cigsale,
    unit = state,
    time = year,
    i_unit = "California",
    i_time = 1988,
    generate_placebos = TRUE
  ) |> 
  # The first three predictors
  generate_predictor(
    time_window = 1976:1988, # Changed time window
    lnincome = mean(lnincome, na.rm = TRUE),
    retprice = mean(retprice, na.rm = TRUE),
    age15to24 = mean(age15to24, na.rm = TRUE)
  ) |> 
  # Removed beer consumption in 1984-1988
  # Cigarette sales in 1975
  generate_predictor(
    time_window = 1975,
    cigsale_1975 = cigsale
  ) |> 
  # Cigarette sales in 1980
  generate_predictor(
    time_window = 1980,
    cigsale_1980 = cigsale
  ) |> 
  # Added cigarette sales in 1984
  generate_predictor(
    time_window = 1984,
    cigsale_1984 = cigsale
  ) |> 
  # Cigarette sales in 1988
  generate_predictor(
    time_window = 1988,
    cigsale_1988 = cigsale
  )

# compute variance for each predictor
v_weights <- 
  grab_predictors(prop99_syn_robust, type = "controls") |> 
  pivot_longer(-variable) |> 
  group_by(variable) |> 
  summarize(inverse_var = 1/var(value)) |> 
  mutate(v_weight = inverse_var/sum(inverse_var)) |> 
  pull(v_weight)

# create weights and synthetic control
prop99_syn_robust <- 
  prop99_syn_robust |> 
  generate_weights(custom_variable_weights = v_weights) |> 
  generate_control()

# plot the trend and permutation test
plot_trends(prop99_syn_robust)
plot_placebos(prop99_syn_robust)
```
:::



## Interrupted Time Series (Bonus)

For this part of the practical, we will use `fpp3` to fit a time-series model to our data. Install and load this package before we get started

```{r}
#| label: setup-3
#| code-fold: false
#| message: false
#| warning: false
#| eval: true
library(fpp3) # For synthetic control analysis
```


First, we need to transform our dataset into a `tsibble` (a time-series table object). This is necessary for the `fpp3` package to figure out which column indicates time. We also only need the cigarette sales data from California for this practical You can prepare the data by running the following code

```{r}
#| label: tsibble
#| eval: true
#| code-fold: false

# try to figure out what each line does!
prop99_ts <- 
  prop99 |> 
  filter(state == "California") |> 
  select(year, cigsale) |>
  mutate(prepost = factor(year > 1988, labels = c("Pre", "Post"))) |> 
  as_tsibble(index = year) |> 
  mutate(year0 = year - 1989)
```

Note that we have also already included a `prepost` variable in the preparation which can be used to filter the pre or post-intervention time-series.

::: {.callout-note}
## Exercise 15
Create the linear growth curve model from the slides: use linear regression to predict cigarette sales with the time variable `year` in the pre-intervention period. What is the estimated year-over-year decrease in cigarette sales?

```{r}
#| label: growthcurve

# here fit a very simple growth curve simple model
fit_growth <- lm(
  formula = cigsale ~ year, 
  prop99_ts |> filter(prepost == "Pre")
)

summary(fit_growth)
# here we see a negative slope; decrease of 1.78 per year
```
:::



::: {.callout-note}
## Exercise 16
Create predictions for the post-intervention period from this model. Then, estimate and interpret the causal effect(s) of the policy. 

```{r}
#| label: growthpred
pred <- predict(
  object = fit_growth, 
  newdata = prop99_ts |> filter(prepost == "Post")
)

# effect at each time-point T
ce_growth <- prop99_ts |> filter(prepost == "Post") |> pull(cigsale) - pred

# You could summarize these effects by taking the mean of them
mean(ce_growth)

# on average, 28.27 fewer cigarette packages per 100000 
# people sold each year due to the intervention
```
:::


Time-series techniques also take into account autocorrelations and the idea that recent values of the outcome of interest have more predictive power over the current value than values far in the past. With the `fpp3` package, we can do a data-driven model selection for the proposition 99 dataset and produce a counterfactual with automatic uncertainty quantification.

::: {.callout-note}
## Exercise 17

Fit an `ARIMA()` model using only the pre-intervention cigarette sales data in California. Then, using the `forecast()` function, create forecasts for 12 years and plot those forecasts with the `autoplot()` function. What do you notice about the uncertainty in this plot?

```{r}
#| label: arima

# create ARIMA model. NB: this user interface of the
# FPP3 package is slightly idiosyncratic. Don't worry
# too much about it!
fit_arima <-  
  prop99_ts |> 
  filter(prepost == "Pre") |> 
  # here we use the corrected AIC to do model selection
  # many other methods of model selection are also 
  # possible (e.g. cross-validation)
  model(timeseries = ARIMA(cigsale, ic = "aicc")) 

# create forecasts
fcasts <- forecast(fit_arima, h = "12 years") 

# plot the forecasts
fcasts |> autoplot(prop99_ts)

# Uncertainty interval becomes wider as we move further
# in time.
```
:::

::: {.callout-note}
## Exercise 18

Use the ARIMA forecasts to estimate the causal effect of the proposition 99 policy intervention.

```{r}
#| label: arima-estimate

observed_cigsale <- 
  prop99_ts |> 
  filter(prepost == "Post") |> 
  pull(cigsale)

# you can use the predicted means directly
mean(fcasts$.mean - observed_cigsale)

# or you can get a prediction interval of the differences
# by using the distribution objects in the forecasts
# again, very idiosyncratic interface but this is how you
# could get uncertainty around your ACE estimate
ace_distribution <- sum(fcasts$cigsale - observed_cigsale) / 12
ace_distribution

# using the hilo function you can get 95% intervals:
hilo(ace_distribution)

# So the ACE is small and not significantly different from 0
```
:::


